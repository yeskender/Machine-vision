{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern recognition: Lab 7\n",
    "### Tasks:\n",
    "* Plot the error\n",
    "* Model XOR with the help of sigmoid\n",
    "* Add moments rule to learning equation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 1\n",
    "def sigmoid(x):#ошибки здесь 2 задание\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1.0-x)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1.0 - x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 10000\n",
      "epochs: 20000\n",
      "epochs: 30000\n",
      "epochs: 40000\n",
      "epochs: 50000\n",
      "epochs: 60000\n",
      "epochs: 70000\n",
      "epochs: 80000\n",
      "epochs: 90000\n",
      "[0 0] [-0.00029731]\n",
      "[0 1] [ 0.99524146]\n",
      "[1 0] [ 0.99503926]\n",
      "[1 1] [ -4.06385598e-05]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers, activation='sigmoid'):\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = sigmoid\n",
    "            self.activation_prime = sigmoid_prime\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = tanh\n",
    "            self.activation_prime = tanh_prime\n",
    "\n",
    "        # Set weights\n",
    "        self.weights = []\n",
    "        # layers = [2,2,1]\n",
    "        # range of weight values (-1,1)\n",
    "        # input and hidden layers - random((2+1, 2+1)) : 3 x 3\n",
    "        \n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
    "            self.weights.append(r)\n",
    "        # output layer - random((2+1, 1)) : 3 x 1\n",
    "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "        self.weights.append(r)\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=100000):\n",
    "        # Add column of ones to X\n",
    "        # This is to add the bias unit to the input layer\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.concatenate((ones.T, X), axis=1)\n",
    "         \n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "\n",
    "            for l in range(len(self.weights)):\n",
    "                    dot_value = np.dot(a[l], self.weights[l])\n",
    "                    activation = self.activation(dot_value)\n",
    "                    a.append(activation)\n",
    "            # output layer\n",
    "            error = y[i] - a[-1]#Нарисовать эррор\n",
    "            deltas = [error * self.activation_prime(a[-1])]\n",
    "\n",
    "            # we need to begin at the second to last layer \n",
    "            # (a layer before the output layer)\n",
    "            for l in range(len(a) - 2, 0, -1): \n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "\n",
    "            # reverse\n",
    "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "            deltas.reverse()\n",
    "\n",
    "            # backpropagation\n",
    "            # 1. Multiply its output delta and input activation \n",
    "            #    to get the gradient of the weight.\n",
    "            # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)#здесь нужно добавить веса моменты 3 задание \n",
    "\n",
    "            if k % 10000 == 0: \n",
    "                print('epochs:', k)\n",
    "\n",
    "    def predict(self, x): \n",
    "    \n",
    "        a = np.concatenate((np.ones(1).T, np.array(x)))      \n",
    "\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        return a\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,1])\n",
    "    X = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "#     X = np.array([[-1, -1],\n",
    "#                   [-1, 1],\n",
    "#                   [1, -1],\n",
    "#                   [1, 1]])\n",
    "#     y = np.array([0, 1, 1, 0])\n",
    "\n",
    "    nn.fit(X, y)\n",
    "    for e in X:\n",
    "        print(e,nn.predict(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01288374]\n",
      " [ 0.99224013]\n",
      " [ 0.99223978]\n",
      " [ 0.00198238]]\n"
     ]
    }
   ],
   "source": [
    "#   XOR.py-A very simple neural network to do exclusive or.\n",
    "import numpy as np\n",
    " \n",
    "epochs = 60000           # Number of iterations\n",
    "inputLayerSize, hiddenLayerSize, outputLayerSize = 2, 3, 1\n",
    " \n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = np.array([ [0],   [1],   [1],   [0]])\n",
    "def sigmoid(x):#ошибки здесь 2 задание\n",
    "    return 1.0/(1.0 + np.exp(-k*x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1.0-sigmoid(x))\n",
    "def sigmoid (x): return 1/(1 + np.exp(-x))      # activation function\n",
    "def sigmoid_(x): return x * (1 - x)             # derivative of sigmoid\n",
    "                                                # weights on layer inputs\n",
    "Wh = np.random.uniform(size=(inputLayerSize, hiddenLayerSize))\n",
    "Wz = np.random.uniform(size=(hiddenLayerSize,outputLayerSize))\n",
    " \n",
    "for i in range(epochs):\n",
    " \n",
    "    H = sigmoid(np.dot(X, Wh))                  # hidden layer results\n",
    "    Z = sigmoid(np.dot(H, Wz))                  # output layer results\n",
    "    E = Y - Z                                   # how much we missed (error)\n",
    "    dZ = E * sigmoid_(Z)                        # delta Z\n",
    "    dH = dZ.dot(Wz.T) * sigmoid_(H)             # delta H\n",
    "    Wz +=  H.T.dot(dZ)                          # update output layer weights\n",
    "    Wh +=  X.T.dot(dH)                          # update hidden layer weights\n",
    "     \n",
    "print(Z)                # what have we learnt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b22a22cba570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0msyn0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;31m# forward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0ml0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "# sigmoid function\n",
    "def nonlin(x,deriv=False):\n",
    "    if(deriv==True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# input dataset\n",
    "X = np.array([  [0,0,1],\n",
    "                [0,1,1],\n",
    "                [1,0,1],\n",
    "                [1,1,1] ])\n",
    " \n",
    "# output dataset           \n",
    "y = np.array([[0,0,1,1]]).T\n",
    " \n",
    "# seed random numbers to make calculation\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(1)\n",
    " \n",
    "# initialize weights randomly with mean 0\n",
    "syn0 = 2*np.random.random((3,1)) - 1\n",
    " \n",
    "for iter in xrange(10000):\n",
    "    # forward propagation\n",
    "    l0 = X\n",
    "    l1 = nonlin(np.dot(l0,syn0))\n",
    "\n",
    "    # how much did we miss?\n",
    "    l1_error = y - l1\n",
    "    # multiply how much we missed by the\n",
    "    # slope of the sigmoid at the values in l1\n",
    "    l1_delta = l1_error * nonlin(l1,True)\n",
    "\n",
    "    # update weights\n",
    "    syn0 += np.dot(l0.T,l1_delta)\n",
    " \n",
    "\n",
    "print(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-e0b78da73f64>, line 75)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-e0b78da73f64>\"\u001b[0;36m, line \u001b[0;32m75\u001b[0m\n\u001b[0;31m    print n.rmse(X, T)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy\n",
    "import scipy\n",
    "import scipy.special\n",
    "import matplotlib\n",
    "#from pylab import *\n",
    "\n",
    "#numpy.random.seed(23)\n",
    "\n",
    "def nmap(f, x):\n",
    "    return numpy.array(map(f, x))\n",
    "\n",
    "class Net:\n",
    "    def __init__(self, *sizes):\n",
    "        self.hidden_layers = len(sizes)-2\n",
    "        self.weights = [numpy.random.uniform(-1, 1, (sizes[i+1],sizes[i])) for i in range(self.hidden_layers+1)]\n",
    "\n",
    "    @staticmethod\n",
    "    def activate(x):\n",
    "        return scipy.special.expit(x)\n",
    "        #return 1/(1+numpy.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def activate_(x):\n",
    "        s = scipy.special.expit(x)\n",
    "        return s*(1-s)\n",
    "\n",
    "    def y(self, x):\n",
    "        o = [numpy.array(x)] #o[i] is the (activated) output of hidden layer i, \"hidden layer 0\" is inputs and not activated\n",
    "        for weight in self.weights[:-1]:\n",
    "            o.append(Net.activate(weight.dot(o[-1])))\n",
    "        o.append(self.weights[-1].dot(o[-1]))\n",
    "#        for weight in self.weights:\n",
    "#            o.append(Net.activate(weight.dot(o[-1])))\n",
    "        return o\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.y(x)[-1]\n",
    "\n",
    "    def delta(self, x, t):\n",
    "        x = numpy.array(x)\n",
    "        t = numpy.array(t)\n",
    "        o = self.y(x)\n",
    "        #delta = [(o[-1]-t) * o[-1] * (1-o[-1])]\n",
    "        delta = [o[-1]-t]\n",
    "        for i, weight in enumerate(reversed(self.weights)):\n",
    "            delta.append(weight.T.dot(delta[-1]) * o[-i-2] * (1-o[-i-2]))\n",
    "        delta.reverse() #surely i need this\n",
    "        return o, delta\n",
    "\n",
    "    def train(self, inputs, outputs, epochs=1000, rate=.1):\n",
    "        errors = []\n",
    "        for epoch in range(epochs):\n",
    "            for x, t in zip(inputs, outputs): #shuffle? subset?\n",
    "                o, d = self.delta(x, t)\n",
    "                for layer in range(self.hidden_layers+1):\n",
    "                    grad = numpy.outer(d[layer+1], o[layer])\n",
    "                    self.weights[layer] -=  rate * grad\n",
    "\n",
    "        return errors\n",
    "\n",
    "    def rmse(self, inputs, outputs):\n",
    "        return ((outputs - nmap(self, inputs))**2).sum()**.5/len(inputs)\n",
    "\n",
    "\n",
    "\n",
    "n = Net(1, 8, 1)\n",
    "X = numpy.linspace(0, 2*3.1415, 10)\n",
    "T = numpy.sin(X)\n",
    "Y = map(n, X)\n",
    "Y = numpy.array([y[0,0] for y in Y])\n",
    "matplotlib.pyplot.plot(X, T, 'g')\n",
    "matplotlib.pyplot.plot(X, Y, 'r')\n",
    "print('output successful')\n",
    "print n.rmse(X, T)\n",
    "errors = n.train(X, T)\n",
    "print('tried to train successfully')\n",
    "print(n.rmse(X, T))\n",
    "Y = map(n, X)\n",
    "Y = numpy.array([y[0,0] for y in Y])\n",
    "matplotlib.pyplot.plot(x, Y, 'b')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output successful\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'float' and 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e56625566496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output successful'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tried to train successfully'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-e56625566496>\u001b[0m in \u001b[0;36mrmse\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'map'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy\n",
    "import scipy\n",
    "import scipy.special\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#from pylab import *\n",
    "\n",
    "#numpy.random.seed(23)\n",
    "\n",
    "def nmap(f, x):\n",
    "    return numpy.array(map(f, x))\n",
    "\n",
    "class Net:\n",
    "    def __init__(self, *sizes):\n",
    "        self.hidden_layers = len(sizes)-2\n",
    "        self.weights = [numpy.random.uniform(-1, 1, (sizes[i+1],sizes[i])) for i in range(self.hidden_layers+1)]\n",
    "\n",
    "    @staticmethod\n",
    "    def activate(x):\n",
    "        return scipy.special.expit(x)\n",
    "        #return 1/(1+numpy.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def activate_(x):\n",
    "        s = scipy.special.expit(x)\n",
    "        return s*(1-s)\n",
    "\n",
    "    def y(self, x):\n",
    "        o = [numpy.array(x)] #o[i] is the (activated) output of hidden layer i, \"hidden layer 0\" is inputs and not activated\n",
    "        for weight in self.weights[:-1]:\n",
    "            o.append(Net.activate(weight.dot(o[-1])))\n",
    "        o.append(self.weights[-1].dot(o[-1]))\n",
    "#        for weight in self.weights:\n",
    "#            o.append(Net.activate(weight.dot(o[-1])))\n",
    "        return o\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.y(x)[-1]\n",
    "\n",
    "    def delta(self, x, t):\n",
    "        x = numpy.array(x)\n",
    "        t = numpy.array(t)\n",
    "        o = self.y(x)\n",
    "        #delta = [(o[-1]-t) * o[-1] * (1-o[-1])]\n",
    "        delta = [o[-1]-t]\n",
    "        for i, weight in enumerate(reversed(self.weights)):\n",
    "            delta.append(weight.T.dot(delta[-1]) * o[-i-2] * (1-o[-i-2]))\n",
    "        delta.reverse() #surely i need this\n",
    "        return o, delta\n",
    "\n",
    "    def train(self, inputs, outputs, epochs=1000, rate=.1):\n",
    "        errors = []\n",
    "        for epoch in range(epochs):\n",
    "            for x, t in zip(inputs, outputs): #shuffle? subset?\n",
    "                o, d = self.delta(x, t)\n",
    "                for layer in range(self.hidden_layers+1):\n",
    "                    grad = numpy.outer(d[layer+1], o[layer])\n",
    "                    self.weights[layer] -=  rate * grad\n",
    "\n",
    "        return errors\n",
    "\n",
    "    def rmse(self, inputs, outputs):\n",
    "        return ((outputs - nmap(self, inputs))**2).sum()**.5/len(inputs)\n",
    "\n",
    "\n",
    "\n",
    "n = Net(1, 8, 1)\n",
    "X = numpy.linspace(0, 2*3.1415, 10)\n",
    "T = numpy.sin(X)\n",
    "Y = map(n, X)\n",
    "Y = numpy.array([y[0,0] for y in Y])\n",
    "matplotlib.pyplot.plot(X, T, 'g')\n",
    "matplotlib.pyplot.plot(X, Y, 'r')\n",
    "print('output successful')\n",
    "print(n.rmse(X, T))\n",
    "errors = n.train(X, T)\n",
    "print('tried to train successfully')\n",
    "print(n.rmse(X, T))\n",
    "Y = map(n, X)\n",
    "Y = numpy.array([y[0,0] for y in Y])\n",
    "matplotlib.plt.plot(x, Y, 'b')\n",
    "matplotlib.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
